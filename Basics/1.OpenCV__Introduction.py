# -*- coding: utf-8 -*-
"""1.OpenCV__Introduction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ksrkRmvTguH7MFAXwIzFdwzCRi2LdMBL

BASICS:

INTRODUCTION TO IMAGES
INSTALLATION

TOPICS:

1. Read Images Videos and Web cams.
2. Basic Functions.
3. Resizing and cropping.
4. Shapes and Text.
5. Warp Prespective.
6. Joining Images.
7. Color Detection.
8. Contour/Shape Detection.
9. Face Detection.

PROJECTS:

1. Virtual Paint
2. Paper Scanner
3. Number Plate Detector

**INTRODUCTION TO IMAGES:**

* For displaying a number, suppose we have a grid of nxn. Certain grids will be colored to display a number. Some boxes will be white in color while others will be black.
* We can denote all the black boxes(written) as '0' while white boxes as '1' in the grid.
* Example we have a grid of 10x10.

VGA=640X480

HD=1280X720

FHD=1920X1080

4K=3840X2160

* All of these represents particular number of pixels.
* Binary image(Black and white image) has only two pixel values 0/1.
* In order to have more colors we will need to have a range of values.
* Example: 6 levels, 16 levels of grey.
* For having a clear image we will have 2^8=256 levels or resolution value with 8 bits. Where 0 will be black and 255 will be white and the range between 0-255 will be shades from black to white. This image is known as **Gray scale image**.
* Similarly, for color images we have three scales representing each of red, green and blue.
* Adding these three RGB values will give a complete colored image. Which also means a colored image will have HeightxWidthxChannel.
* Example for VGA: 640x480x3

(Python 3.7.6 works well with open CV)

**1. READ IMAGES, VIDEOS AND WEBCAMS:**
"""

######################## READ IMAGE ############################

import cv2
# # LOAD AN IMAGE USING 'IMREAD'
img = cv2.imread("Resources/lena.png")
# # DISPLAY
cv2.imshow("Lena Soderberg",img)
cv2.waitKey(0)  # in miliseconds

######################### READ VIDEO #############################

import cv2
frameWidth = 640
frameHeight = 480
cap = cv2.VideoCapture("Resources/test_ video.mp4")
#While loop to go through each frame one by one.
while True:
    success, img = cap.read() #success will be boolean value and image will store frames.
    img = cv2.resize(img, (frameWidth, frameHeight))
    cv2.imshow("Result", img)
    if cv2.waitKey(1) & 0xFF == ord('q'): #press q to stop
        break

######################### READ WEBCAM  ############################

import cv2
frameWidth = 640
frameHeight = 480
cap = cv2.VideoCapture(0) #from webcam
cap.set(3, frameWidth)  #width
cap.set(4, frameHeight) #height
cap.set(10,150) #Brightness
while True:
    success, img = cap.read()
    cv2.imshow("Result", img)
    if cv2.waitKey(1) & 0xFF == ord('q'):
        break

"""2. **BASIC FUNCTIONS**"""

import cv2
import numpy as np

img = cv2.imread("Resources/lena.png")
kernel = np.ones((5,5),np.uint8)  #value can range from 0 to 255

imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY) #Convert to gray scale
imgBlur = cv2.GaussianBlur(imgGray,(7,7),0) #blurr the image, kernel size, sigmax
imgCanny = cv2.Canny(img,150,200) #edge detector, threshold values.
imgDialation = cv2.dilate(imgCanny,kernel,iterations=1) #Increase the thickness of edge(connect the edges for clear image.)
#kernel with all ones matrix
#iter= thickness in border/edges
imgEroded = cv2.erode(imgDialation,kernel,iterations=1)
#opposite to dialation

cv2.imshow("Gray Image",imgGray)
cv2.imshow("Blur Image",imgBlur)
cv2.imshow("Canny Image",imgCanny)
cv2.imshow("Dialation Image",imgDialation)
cv2.imshow("Eroded Image",imgEroded)
cv2.waitKey(0)

"""3. **RESIZING AND CROPPING**

* In openCV, the positive x axis is towards east while the positive y axis is towards south.
* Example for an image of size 640x480, x axis distance is 640(east) while the y axis distance is 480(south). origin of image will be at top left corner(0,0) and max height and width will be at bottom right(640,480).
"""

import cv2
import numpy as np

img = cv2.imread("Resources/shapes.png")
print(img.shape)  # initial shape, eg(462,623,3)=(Height,width,channel:BGR)

imgResize = cv2.resize(img,(1000,500)) # NOTE THE FORMAT IS: (width, height)
print(imgResize.shape)  #200,300,3
# We can also increase the image size but quality rmains the same

imgCropped = img[46:119,352:495] #NOTE AGAIN: height, width

cv2.imshow("Image",img)
#cv2.imshow("Image Resize",imgResize)
cv2.imshow("Image Cropped",imgCropped)

cv2.waitKey(0)

"""4. **SHAPES AND TEXTS**

* Drawing shapes and texts on images.
"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
img = np.zeros((512,512,3),np.uint8)  #0 is black and np.units8 gives the values from 0 to 255
#print(img)
#img[:]= 255,0,0  #Changing the complete image to blue
# ':' specifies the height and width 
# we can also specify as img[200:300,100:300]

cv2.line(img,(0,0),(img.shape[1],img.shape[0]),(0,255,0),3)
# specify img, start pt, end pt, color, thickness:of line
# if we want to extend the line till the end:
# height,width=(img.shape[1],img.shape[0])

cv2.rectangle(img,(0,0),(250,350),(0,0,255),2)
# for filled image:
# cv2.rectangle(img,(0,0),(250,350),(0,0,255),cv2.FILLED)
cv2.circle(img,(400,50),30,(255,255,0),5)
#CENTER, RADIUS, COLOR
cv2.putText(img," OPENCV  ",(300,200),cv2.FONT_HERSHEY_COMPLEX,1,(0,150,0),3)
#start,font,scale,color,thickness

cv2_imshow(img)

cv2.waitKey(0)

"""5. **WARP PERSPECTIVE**"""

import cv2
import numpy as np

img = cv2.imread("Resources/cards.jpg")
#selecting a part of image

width,height = 250,350
pts1 = np.float32([[111,219],[287,188],[154,482],[352,440]])
#Values of pixels
pts2 = np.float32([[0,0],[width,0],[0,height],[width,height]])
#define the specification of above pixels
matrix = cv2.getPerspectiveTransform(pts1,pts2)
imgOutput = cv2.warpPerspective(img,matrix,(width,height))


cv2.imshow("Image",img)
cv2.imshow("Output",imgOutput)

cv2.waitKey(0)

"""6. **JOINING IMAGES**"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow
#all images in one window
#basic commands to stack:
# img =cv2.imread('Resourses/lena.png')
# imgHor=np.hstack((img,img)) #two images side by side
# imgVer=np.vstack((img,img)) #two images up and down
#but we cannot resize it and have to have same number of channels

def stackImages(scale,imgArray):
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range ( 0, rows):
            for y in range(0, cols):
                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)
                else:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)
                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)
        imageBlank = np.zeros((height, width, 3), np.uint8)
        hor = [imageBlank]*rows
        hor_con = [imageBlank]*rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:
                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)
            else:
                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)
            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)
        hor= np.hstack(imgArray)
        ver = hor
    return ver

img = cv2.imread('lena.png')
imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #gray

imgStack = stackImages(0.5,([img,imgGray,img],[img,img,img]))
#scale,matrices of img(horizontal_stack,vertical_stack)

# imgHor = np.hstack((img,img))
# imgVer = np.vstack((img,img))
#
# cv2.imshow("Horizontal",imgHor)
# cv2.imshow("Vertical",imgVer)
cv2_imshow(imgStack)

cv2.waitKey(0)

"""7. **COLOR DETECTION**"""

import cv2
import numpy as np

def empty(a):
    pass

def stackImages(scale,imgArray):
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range ( 0, rows):
            for y in range(0, cols):
                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)
                else:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)
                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)
        imageBlank = np.zeros((height, width, 3), np.uint8)
        hor = [imageBlank]*rows
        hor_con = [imageBlank]*rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:
                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)
            else:
                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)
            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)
        hor= np.hstack(imgArray)
        ver = hor
    return ver



path = 'lambo.png'  #aim to find orange color: create color hue using trackbars 
cv2.namedWindow("TrackBars")
cv2.resizeWindow("TrackBars",640,240) #size
cv2.createTrackbar("Hue Min","TrackBars",0,179,empty) #initial,max(maxis 360 but in opencv it is 179)
cv2.createTrackbar("Hue Max","TrackBars",19,179,empty)
cv2.createTrackbar("Sat Min","TrackBars",110,255,empty)
cv2.createTrackbar("Sat Max","TrackBars",240,255,empty)
cv2.createTrackbar("Val Min","TrackBars",153,255,empty)
cv2.createTrackbar("Val Max","TrackBars",255,255,empty)
# apply to image now

while True:
    img = cv2.imread(path)
    imgHSV = cv2.cvtColor(img,cv2.COLOR_BGR2HSV)  #convert to HSV
    h_min = cv2.getTrackbarPos("Hue Min","TrackBars")# get position
    h_max = cv2.getTrackbarPos("Hue Max", "TrackBars")
    s_min = cv2.getTrackbarPos("Sat Min", "TrackBars")
    s_max = cv2.getTrackbarPos("Sat Max", "TrackBars")
    v_min = cv2.getTrackbarPos("Val Min", "TrackBars")
    v_max = cv2.getTrackbarPos("Val Max", "TrackBars")
    print(h_min,h_max,s_min,s_max,v_min,v_max)
    lower = np.array([h_min,s_min,v_min])
    upper = np.array([h_max,s_max,v_max])
    mask = cv2.inRange(imgHSV,lower,upper)  #changing trackbar of mask set to orange n note the value
    #its B/W
    imgResult = cv2.bitwise_and(img,img,mask=mask)  #original filtered image


    # cv2.imshow("Original",img)
    # cv2.imshow("HSV",imgHSV)
    # cv2.imshow("Mask", mask)
    # cv2.imshow("Result", imgResult)

    imgStack = stackImages(0.6,([img,imgHSV],[mask,imgResult]))
    cv2.imshow("Stacked Images", imgStack)

    cv2.waitKey(1)

"""8. **CONTOURS/SHAPE DETECTION**"""

import cv2
import numpy as np
from google.colab.patches import cv2_imshow

def stackImages(scale,imgArray):
    rows = len(imgArray)
    cols = len(imgArray[0])
    rowsAvailable = isinstance(imgArray[0], list)
    width = imgArray[0][0].shape[1]
    height = imgArray[0][0].shape[0]
    if rowsAvailable:
        for x in range ( 0, rows):
            for y in range(0, cols):
                if imgArray[x][y].shape[:2] == imgArray[0][0].shape [:2]:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (0, 0), None, scale, scale)
                else:
                    imgArray[x][y] = cv2.resize(imgArray[x][y], (imgArray[0][0].shape[1], imgArray[0][0].shape[0]), None, scale, scale)
                if len(imgArray[x][y].shape) == 2: imgArray[x][y]= cv2.cvtColor( imgArray[x][y], cv2.COLOR_GRAY2BGR)
        imageBlank = np.zeros((height, width, 3), np.uint8)
        hor = [imageBlank]*rows
        hor_con = [imageBlank]*rows
        for x in range(0, rows):
            hor[x] = np.hstack(imgArray[x])
        ver = np.vstack(hor)
    else:
        for x in range(0, rows):
            if imgArray[x].shape[:2] == imgArray[0].shape[:2]:
                imgArray[x] = cv2.resize(imgArray[x], (0, 0), None, scale, scale)
            else:
                imgArray[x] = cv2.resize(imgArray[x], (imgArray[0].shape[1], imgArray[0].shape[0]), None,scale, scale)
            if len(imgArray[x].shape) == 2: imgArray[x] = cv2.cvtColor(imgArray[x], cv2.COLOR_GRAY2BGR)
        hor= np.hstack(imgArray)
        ver = hor
    return ver

def getContours(img):
    contours,hierarchy = cv2.findContours(img,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)
    #RETR_EXTERNAL for outer contour
    for cnt in contours:
        area = cv2.contourArea(cnt)
        print(area)
        if area>500:
            cv2.drawContours(imgContour, cnt, -1, (255, 0, 0), 3) #indexes
            peri = cv2.arcLength(cnt,True)  #corners, true if closed
            #print(peri)
            approx = cv2.approxPolyDP(cnt,0.02*peri,True) #corner pts
            print(len(approx))  #number of corners
            objCor = len(approx)
            x, y, w, h = cv2.boundingRect(approx)

            if objCor ==3: objectType ="Tri"
            elif objCor == 4:
                aspRatio = w/float(h)
                if aspRatio >0.98 and aspRatio <1.03: objectType= "Square"
                else:objectType="Rectangle"
            elif objCor>4: objectType= "Circles"
            else:objectType="None"



            cv2.rectangle(imgContour,(x,y),(x+w,y+h),(0,255,0),2)
            cv2.putText(imgContour,objectType,
                        (x+(w//2)-10,y+(h//2)-10),cv2.FONT_HERSHEY_COMPLEX,0.7,
                        (0,0,0),2)




path = 'shapes.png'
img = cv2.imread(path)
imgContour = img.copy()

imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)  #grey scale
imgBlur = cv2.GaussianBlur(imgGray,(7,7),1) #1: sigma, if increases it will b blurred more
imgCanny = cv2.Canny(imgBlur,50,50) #find edges, threshold values
getContours(imgCanny)

imgBlank = np.zeros_like(img)
imgStack = stackImages(0.8,([img,imgGray,imgBlur],
                            [imgCanny,imgContour,imgBlank]))

cv2_imshow( imgStack)

cv2.waitKey(0)

"""9. **FACE DETECTION**

* Positive faces: Faces
* Negative Non faces
* these two will be used to train and find xml file. Although, we will use pretrain provided by OpenCV Cascades.
"""

import cv2
#use available classifier.
faceCascade= cv2.CascadeClassifier("Resources/haarcascade_frontalface_default.xml")
img = cv2.imread('Resources/lena.png')
imgGray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)

faces = faceCascade.detectMultiScale(imgGray,1.1,4) #scale, neighbor

for (x,y,w,h) in faces:
    cv2.rectangle(img,(x,y),(x+w,y+h),(255,0,0),2)  #start corner, diagonal corner


cv2_imshow("Result", img)
cv2.waitKey(0)